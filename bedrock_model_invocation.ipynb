{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00efd7c2",
   "metadata": {},
   "source": [
    "# Bedrock Model Invocation\n",
    "This notebook contains a Python script to invoke various Bedrock models. The script defines functions to select and interact with different AI models like TITAN, CLAUDE, and others, using the Bedrock API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675cbfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Weaviate is an open-source vector search engine for unstructured data. Some key things it does and common use cases include:\n",
      "\n",
      "- Vectorization - It can vectorize and index unstructured data like text, images, videos etc. into high-dimensional vectors. This allows for semantic search capabilities.\n",
      "\n",
      "- Semantic search - Users can perform semantic searches across data by querying vectors. This allows finding concepts and entities that are semantically similar but not identical matches. \n",
      "\n",
      "- Knowledge graph construction - It can be used to build knowledge graphs from unstructured data sources where the vectors represent entities, concepts, their properties and relationships. \n",
      "\n",
      "- Recommendation systems - The semantic search capabilities make it suitable for building recommendation engines across product catalogs, content etc. \n",
      "\n",
      "- Question answering - By understanding relationships between concepts, it can help build virtual assistants and chatbots that can answer natural language questions.\n",
      "\n",
      "- Text analytics - Functions like clustering, classification and topic modeling using vector embeddings help in applications like text summarization, sentiment analysis etc. \n",
      "\n",
      "- Computer vision - It supports vectorization of images/videos and thus can be used for image/video search, annotation and other visual data applications.\n",
      "\n",
      "So in summary, common uses include semantic search, knowledge graphs, recommendations, question answering, text and visual analytics where understanding relationships is important.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "def invoke_bedrock_model(model_type, template, max_tokens, temperature, top_p, stop_sequences):\n",
    "    \"\"\"\n",
    "    Invoke a Bedrock model based on the given model type and parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - model_type (str): The type of the model (e.g., \"TITAN\", \"CLAUDE\", etc.)\n",
    "    - template (str): The prompt for the model.\n",
    "    - max_tokens (int): Maximum number of tokens to sample.\n",
    "    - temperature (float): Sampling temperature.\n",
    "    - top_p (float): Top-p sampling value.\n",
    "    - stop_sequences (list): List of sequences to stop the sampling.\n",
    "\n",
    "    Returns:\n",
    "    - None: Prints the model's completion.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the model ID based on the provided model type\n",
    "    if model_type == \"TITAN\":\n",
    "        model_id = \"amazon.titan-tg1-large\"\n",
    "    elif model_type == \"CLAUDE\":\n",
    "        model_id = \"anthropic.claude-v1\"\n",
    "    elif model_type == \"CLAUDE-INSTANT\":\n",
    "        model_id = \"anthropic.claude-instant-v1\"\n",
    "    elif model_type == \"J2\":\n",
    "        model_id = \"ai21.j2-jumbo-instruct\"\n",
    "    else:\n",
    "        # Handle unsupported models\n",
    "        raise Exception(\"Unsupported model\")\n",
    "\n",
    "    # Initialize the Bedrock client\n",
    "    bedrock = boto3.client('bedrock-runtime')\n",
    "\n",
    "    # Prepare the request body with the parameters\n",
    "    body = {\n",
    "        \"prompt\": template,\n",
    "        \"max_tokens_to_sample\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"stop_sequences\": stop_sequences\n",
    "    }\n",
    "    body_string = json.dumps(body)\n",
    "\n",
    "    # Invoke the Bedrock model and get the response\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=model_id,\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\",\n",
    "        body=body_string)\n",
    "\n",
    "    # Parse the response and print the completion\n",
    "    json_obj = json.loads(response.get(\"body\").read().decode())\n",
    "    print(json_obj['completion'])\n",
    "\n",
    "\n",
    "def bedrock_smoke_test():\n",
    "    # Example usage of the invoke_bedrock_model function\n",
    "    model_type=\"CLAUDE-INSTANT\"\n",
    "    prompt = \"What does Redis do ? What are the common use cases supported ?\"\n",
    "    template = f\"\"\"Human: {prompt}\n",
    "                    Assistant:\"\"\"\n",
    "    max_tokens = 5000\n",
    "    max_tokens=2000\n",
    "    stop_sequences=[]\n",
    "    temperature=0\n",
    "    top_p=0.9\n",
    "    invoke_bedrock_model(model_type, template, max_tokens, temperature, top_p, stop_sequences)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Run the smoke test when the script is executed\n",
    "    bedrock_smoke_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff5e2c-b4f8-47ae-8f7b-fce4ef64315f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
